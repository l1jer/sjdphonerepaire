import { NextResponse } from 'next/server'
import { Redis } from '@upstash/redis'

interface Review {
  author_name: string
  author_url: string
  profile_photo_url: string
  rating: number
  relative_time_description: string
  text: string
  time: number
  language?: string
  translated: boolean
}

interface PlaceDetailsResponse {
  result: {
    reviews: Review[]
    rating: number
    user_ratings_total: number
    next_page_token?: string
  }
  status: string
}

interface HistoricalData {
  reviews: Review[]
  last_updated: string
}

interface ResponseData {
  reviews: Review[]
  rating: number
  user_ratings_total: number
  cache_timestamp: string
  reviews_count: number
  historical_reviews?: Review[]
  total_historical_count?: number
  historical_last_updated?: string
}

// Initialize Redis client with provided credentials
const redis = new Redis({
  url: process.env.reviews_KV_REST_API_URL || '',
  token: process.env.reviews_KV_REST_API_TOKEN || ''
})

// Test Redis connection
redis
  .ping()
  .then(() => {
    // console.log('Redis connection successful!')
  })
  .catch(error => {
    console.error('Redis connection failed:', error)
  })

// Use GOOGLE_PLACES_API_KEY instead of NEXT_PUBLIC_ version for server-side
const GOOGLE_PLACES_API_KEY = process.env.GOOGLE_PLACES_API_KEY
const PLACE_ID = 'ChIJncP4AAw51GoRHBRenZ9MLxg'
const CACHE_KEY = 'google_reviews_cache'
const WEEKLY_CACHE_KEY = 'reviews_weekly_cache'
const CACHE_DURATION = 24 * 60 * 60 // 24 hours in seconds
const HISTORICAL_CACHE_KEY = 'google_reviews_historical'

async function getAllReviews (
  placeId: string,
  apiKey: string
): Promise<Review[]> {
  let allReviews: Review[] = []
  const sortTypes = ['most_relevant', 'newest', 'highest_rating']

  for (const sortType of sortTypes) {
    // Build base URL
    const url = new URL(
      'https://maps.googleapis.com/maps/api/place/details/json'
    )
    url.searchParams.append('place_id', placeId)
    url.searchParams.append('key', apiKey)
    url.searchParams.append('language', 'en')
    url.searchParams.append('reviews_sort', sortType)
    url.searchParams.append('reviews_no_translations', 'true')

    console.log(`Fetching reviews with sort type: ${sortType}`)
    const response = await fetch(url.toString())
    const data: PlaceDetailsResponse = await response.json()

    if (data.status !== 'OK') {
      console.error(`API error for ${sortType}:`, data.status)
      continue
    }

    if (data.result.reviews) {
      // Use Set for deduplication based on timestamp and author
      const newReviews = data.result.reviews.filter(
        newReview =>
          !allReviews.some(
            existingReview =>
              existingReview.time === newReview.time &&
              existingReview.author_name === newReview.author_name
          )
      )

      allReviews = [...allReviews, ...newReviews]
      console.log(
        `Fetched ${newReviews.length} unique reviews from ${sortType}. Total unique reviews: ${allReviews.length}`
      )
    }

    // Google API rate limiting, add delay
    await new Promise(resolve => setTimeout(resolve, 2000))
  }

  // Sort by time, newest first, and return exactly 15 reviews
  return allReviews.sort((a, b) => b.time - a.time).slice(0, 15)
}

// API route for handling reviews
export async function GET () {
  if (!GOOGLE_PLACES_API_KEY) {
    console.error('API key missing')
    return NextResponse.json(
      { error: 'Google Places API key not configured' },
      { status: 500 }
    )
  }

  try {
    // First, check weekly cache (primary source)
    console.log('Checking weekly Redis cache...')
    const weeklyCache = await redis.get(WEEKLY_CACHE_KEY)
    if (weeklyCache) {
      console.log('Weekly cache hit! Serving from weekly Redis cache')
      return NextResponse.json(weeklyCache)
    }
    
    // Fallback to daily cache
    console.log('Weekly cache miss! Checking daily Redis cache...')
    const dailyCache = await redis.get(CACHE_KEY)
    if (dailyCache) {
      console.log('Daily cache hit! Serving from daily Redis cache')
      return NextResponse.json(dailyCache)
    }
    
    console.log('No cache found! Fetching from Google API as fallback...')

    // 获取所有评论
    const allReviews = await getAllReviews(PLACE_ID, GOOGLE_PLACES_API_KEY)

    // 获取基本信息
    const basicInfoUrl = new URL(
      'https://maps.googleapis.com/maps/api/place/details/json'
    )
    basicInfoUrl.searchParams.append('place_id', PLACE_ID)
    basicInfoUrl.searchParams.append('key', GOOGLE_PLACES_API_KEY)
    basicInfoUrl.searchParams.append('fields', 'rating,user_ratings_total')

    const basicInfoResponse = await fetch(basicInfoUrl.toString())
    const basicInfoData: PlaceDetailsResponse = await basicInfoResponse.json()

    // Implement rolling cache logic to maintain exactly 15 reviews
    let finalReviews = allReviews

    // Check if we have existing reviews in weekly cache first
    const existingWeeklyCache = await redis.get<ResponseData>(WEEKLY_CACHE_KEY)
    
    if (existingWeeklyCache && existingWeeklyCache.reviews) {
      console.log(`[Daily Sync] Found ${existingWeeklyCache.reviews.length} existing reviews in weekly cache`)
      
      // Merge existing and new reviews, removing duplicates
      const existingReviews = existingWeeklyCache.reviews
      const mergedReviews = [...existingReviews]
      
      // Add new reviews that don't already exist
      for (const newReview of allReviews) {
        const exists = existingReviews.some(existing => 
          existing.time === newReview.time && existing.author_name === newReview.author_name
        )
        if (!exists) {
          mergedReviews.push(newReview)
        }
      }
      
      // Sort by time (newest first)
      const sortedReviews = mergedReviews.sort((a, b) => b.time - a.time)
      
      // If we have fewer than 15 unique reviews, duplicate to reach 15
      if (sortedReviews.length < 15) {
        finalReviews = [...sortedReviews]
        while (finalReviews.length < 15) {
          const remainingSlots = 15 - finalReviews.length
          const reviewsToAdd = sortedReviews.slice(0, Math.min(remainingSlots, sortedReviews.length))
          finalReviews = [...finalReviews, ...reviewsToAdd]
        }
        console.log(`[Daily Sync] Padded ${sortedReviews.length} unique reviews to ${finalReviews.length} total`)
      } else {
        // Take exactly 15 if we have more than 15
        finalReviews = sortedReviews.slice(0, 15)
        console.log(`[Daily Sync] Rolling cache: ${mergedReviews.length} total → ${finalReviews.length} kept (15 limit)`)
      }
    } else {
      // No existing cache, pad with duplicates if needed to reach exactly 15
      if (allReviews.length > 0) {
        finalReviews = [...allReviews]
        
        // Duplicate reviews to reach exactly 15
        while (finalReviews.length < 15) {
          const remainingSlots = 15 - finalReviews.length
          const reviewsToAdd = allReviews.slice(0, Math.min(remainingSlots, allReviews.length))
          finalReviews = [...finalReviews, ...reviewsToAdd]
        }
        
        // Ensure exactly 15 reviews
        finalReviews = finalReviews.slice(0, 15)
      }
      console.log(`[Daily Sync] No existing cache, created initial set of ${finalReviews.length} reviews (from ${allReviews.length} originals)`)
    }

    const responseData: ResponseData = {
      reviews: finalReviews,
      rating: basicInfoData.result.rating || 0,
      user_ratings_total: basicInfoData.result.user_ratings_total || 0,
      cache_timestamp: new Date().toISOString(),
      reviews_count: finalReviews.length
    }

    // Store in Redis cache with expiration
    await redis.set(CACHE_KEY, responseData, {
      ex: CACHE_DURATION
    })

    // Also update the weekly cache with the new rolling data
    await redis.set(WEEKLY_CACHE_KEY, responseData, {
      ex: 7 * 24 * 60 * 60 // 7 days
    })

    // Get historical data if available
    const historicalData = await redis.get<HistoricalData>(HISTORICAL_CACHE_KEY)
    if (historicalData) {
      responseData.historical_reviews = historicalData.reviews
      responseData.total_historical_count = historicalData.reviews.length
      responseData.historical_last_updated = historicalData.last_updated
    }

    console.log('Total reviews collected:', allReviews.length)

    return NextResponse.json(responseData, {
      headers: {
        'Cache-Control': `public, max-age=${CACHE_DURATION}, stale-while-revalidate=${CACHE_DURATION}`
      }
    })
  } catch (error) {
    console.error('Error fetching reviews:', error)
    return NextResponse.json(
      { error: 'Failed to fetch reviews' },
      { status: 500 }
    )
  }
}
